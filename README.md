# **Autocomplete API Scraper - Extract All Names** ğŸš€  

## **ğŸ“Œ Problem Statement**  
We have access to an **autocomplete API** at:  
ğŸ‘‰ `http://35.200.185.69:8000`  

### **Goal:**  
Extract **all possible names** from the API efficiently.  

### **Challenges:**  
1. **No Documentation** â€“ We must explore how the API works.  
2. **Rate Limiting** â€“ Too many requests cause API blocks.  
3. **Efficiency** â€“ Need to minimize duplicate requests and optimize speed.  

---

## **ğŸ” API Exploration & Findings**  

### **1âƒ£ API Endpoint**  
We discovered the API works with:  
```
http://35.200.185.69:8000/v1/autocomplete?query=<string>
```  
ğŸ“Œ **How it works:**  
- `/v1/autocomplete?query=a` â†’ Returns names starting with "a"  
- `/v1/autocomplete?query=ab` â†’ Returns names starting with "ab"  

### **2âƒ£ Rate Limiting & Errors**  
If we send too many requests too fast, we get:  
âŒ **429 Too Many Requests** â€“ API blocks us temporarily.  

### **3âƒ£ Best Strategy to Extract All Names**  
âœ… Start with letters **"a" to "z"**  
âœ… Query the API, get names, and explore further (e.g., `"aa", "ab", "ac"`)  
âœ… Handle rate limits using **adaptive delays and retries**  

---

## **ğŸ’¡ Our Approach**  

### **1âƒ£ Intelligent Query Expansion**  
- Start with **two-character queries** like `"aa", "ab", "ac"`  
- If results are **maxed out**, expand to `"aaa", "aab", "aac"`  

### **2âƒ£ Smart Rate Limiting**  
- We **track API speed** and adjust delays dynamically  
- Implement **automatic retries** for rate-limited queries  

### **3âƒ£ Optimized Storage**  
- Save fetched names in a **set** to avoid duplicates  
- Write results to a file (`output/names_v1.txt`, etc.)  

---

## **âš™ï¸ How to Run the Scraper**  

### **Step 1: Install Dependencies**  
```sh
npm install
```  

### **Step 2: Run the Scraper**  
```sh
node index.js v1
```  
Replace `v1` with `v2` or `v3` for different API versions.  

### **Step 3: View Extracted Names**  
Check the `output/` folder for extracted names.  

---

## **ğŸ“Š Results & Findings**  

Since we only expanded queries when needed, the actual number of searches is much lower.

| API Version       | Brute Force Searches | Optimized Estimated Searches |
|-------------------|----------------------|------------------------------|
| v1 (A-Z)          | 17576 (26*26*26)     | ~4000 - 6000                 |
| v2 (0-9, A-Z)     | 46656 (36*36*36)     | ~8000 - 12000                |
| v3 (Full charset) | 64000 (40*40*40)     | ~12000 - 16000               |

| API Version | Total Requests | Unique Names Extracted |
|------------|--------------   |------------------------|
| v1         |      13048      |         13676          |
| v2         |      ~10000     |         7873           |
| v3         |      9015     |         8533           |

âœ… **Key Discoveries:**  
- API supports **different character sets** per version.  
- **Rate limits vary** (v1 is faster, v3 is more restricted).  
- Expanding queries **improves data coverage**.  

---

## **ğŸ’ï¸â€ğŸ’» Project Structure**  
```
ğŸ“‚ autocomplete-extractor
 â”œâ”€â”€ ğŸ“‚ output/                # Extracted names storage
 â”œâ”€â”€ ğŸ“‚ src/                   # Main code
 â”‚   â”œâ”€â”€ api.js                # API requests & rate limiting
 â”‚   â”œâ”€â”€ scraper.js            # Name extraction logic
 â”‚   â”œâ”€â”€ rateLimiter.js        # Adaptive rate limit handling
 â”‚   â”œâ”€â”€ utils.js              # Helper functions
 â”œâ”€â”€ index.js                  # Main entry point
 â”œâ”€â”€ package.json              # Dependencies
 â”œâ”€â”€ README.md                 # Documentation
```

---

## **ğŸ“¢ Summary**  
âœ… **We successfully extracted all possible names** from the API.  
âœ… **Rate limiting was handled** with dynamic delays & retries.  
âœ… **Optimized query expansion** improved data coverage.  

ğŸ’¡ **Future Improvements:**  
- Parallel requests with **better rate limit tracking**  
- Store extracted data in **a database instead of files**  

